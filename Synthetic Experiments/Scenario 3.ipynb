{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "from copy import deepcopy\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import scipy linear regression\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import t as t_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Boxplot in basic setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 100 # number of experiments\n",
    "T = 1000\n",
    "\n",
    "N = 10 # number of samples per experiment\n",
    "Z = t_dist.ppf(0.975,N)\n",
    "anchor_mean = 1\n",
    "std_niose = 3\n",
    "\n",
    "cost = np.zeros((3,T))\n",
    "accuracy = np.zeros((3,1000))\n",
    "recall = np.zeros((3,1000))\n",
    "FPR = np.zeros((3,1000))\n",
    "precision = np.zeros((3,1000))\n",
    "for t in tqdm(range(T)):\n",
    "\n",
    "    # generate true ATEs\n",
    "    true_tao = np.random.normal(anchor_mean, 3, K )\n",
    "    constant = np.random.normal(anchor_mean, 3)\n",
    "    optimal_cost = np.sum(true_tao[np.argwhere(true_tao>0)])\n",
    "\n",
    "    # generate data\n",
    "    feature = np.ones((N+K, K+1)) \n",
    "    feature[:, 1:] = np.random.binomial(1, 0.5, (N+K,K))\n",
    "\n",
    "    # generate label\n",
    "    label = constant + np.dot(feature[:,1:], true_tao) + np.random.normal(0, std_niose, N+K)\n",
    "\n",
    "    #IHT\n",
    "    model = sm.OLS(label, feature).fit()\n",
    "    estimated_tao = model.params\n",
    "    p_value = model.pvalues[1:]\n",
    "    cov_matrix = model.cov_params()\n",
    "\n",
    "    estimated_variance = np.zeros(K)\n",
    "    for i in range(K):\n",
    "        estimated_variance[i] = cov_matrix[i+1,i+1]\n",
    "\n",
    "    hat_ATE = estimated_tao[1:]\n",
    "\n",
    "    bayesian_tao = np.zeros(K)\n",
    "    bayesian_beta = np.zeros(K)\n",
    "    denumerator = np.var(hat_ATE) - np.mean(estimated_variance)\n",
    "    decision3 = []\n",
    "\n",
    "    for k in range(K):\n",
    "        if denumerator <= 0:\n",
    "            theta = 1\n",
    "            posteri_mean = hat_ATE[k]*theta + (1 - theta)*tau_0\n",
    "            posteri_var = 1/(1/estimated_variance[k])\n",
    "            dist = norm(loc=posteri_mean, scale=np.sqrt(posteri_var))\n",
    "            prob = dist.sf(0)  # survival function: P(X > x)\n",
    "            if prob > 1 - 0.025:\n",
    "                decision3.append(k)\n",
    "        else:\n",
    "            bayesian_beta[k] = max(N*estimated_variance[k]/denumerator,0)\n",
    "            theta = N/(N+bayesian_beta[k])\n",
    "            posteri_mean = hat_ATE[k]*theta + (1 - theta)*tau_0\n",
    "            posteri_var = 1/(1/denumerator+ 1/estimated_variance[k])\n",
    "            dist = norm(loc=posteri_mean, scale=np.sqrt(posteri_var))\n",
    "\n",
    "            prob = dist.sf(0)  # survival function: P(X > x)\n",
    "            if prob > 1 - 0.025:\n",
    "                decision3.append(k)\n",
    "    if optimal_cost == 0:\n",
    "        if len(decision3) == 0:\n",
    "            cost[2,t] = 1\n",
    "        else:\n",
    "            cost[2,t] = 0\n",
    "    else:\n",
    "        cost[2,t] = np.sum(true_tao[decision3])/optimal_cost\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    #estimated cost\n",
    "    decision1 = np.argwhere(hat_ATE>(Z*np.sqrt(estimated_variance)))\n",
    "    cost[0,t] = np.sum(true_tao[decision1])/optimal_cost\n",
    "\n",
    "    \n",
    "    #DRT\n",
    "    tau_0 = np.mean(hat_ATE)\n",
    "    if tau_0 == 0:\n",
    "        cost[1,t] = cost[0,t]\n",
    "        continue\n",
    "    beta = N*np.mean(estimated_variance)/(np.var(hat_ATE) - np.mean(estimated_variance)) +  Z*N*np.sqrt(np.mean(estimated_variance))/tau_0\n",
    "    beta = max(0,beta)\n",
    "    theta = N/(N+beta)\n",
    "    shrunken_ATE = theta*hat_ATE + (1-theta)*tau_0\n",
    "    decision2 = np.argwhere(shrunken_ATE>(theta*Z*np.sqrt(estimated_variance)))\n",
    "\n",
    "    cost[1,t] = np.sum(true_tao[decision2])/optimal_cost\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    for k in range(K):\n",
    "        if (true_tao[k] < 0 and k not in decision1) or (true_tao[k] > 0 and k in decision1):\n",
    "            accuracy[0,t] += 1\n",
    "        if (true_tao[k] < 0 and k not in decision2) or (true_tao[k] > 0 and k in decision2):\n",
    "            accuracy[1,t] += 1\n",
    "        if (true_tao[k] < 0 and k not in decision3) or (true_tao[k] > 0 and k in decision3):\n",
    "                accuracy[2,t] += 1\n",
    "        if true_tao[k] > 0 and k in decision1:\n",
    "            recall[0,t] += 1\n",
    "        if true_tao[k] > 0 and k in decision2:\n",
    "            recall[1,t] += 1\n",
    "        if true_tao[k] > 0 and k in decision3:\n",
    "                recall[2,t] += 1\n",
    "        if true_tao[k] < 0 and k in decision1:\n",
    "            FPR[0,t] += 1\n",
    "        if true_tao[k] <0 and k in decision2:\n",
    "            FPR[1,t] += 1\n",
    "        if true_tao[k] < 0 and k in decision3:\n",
    "                FPR[2,t] += 1\n",
    "    if recall[0,t] + FPR[0,t] == 0:\n",
    "        precision[0,t] = 1\n",
    "    else:\n",
    "        precision[0,t] = recall[0,t]/(recall[0,t] + FPR[0,t] )\n",
    "    if recall[1,t] + FPR[1,t] == 0:\n",
    "        precision[1,t] = 1\n",
    "    else:\n",
    "        precision[1,t] = recall[1,t]/(recall[1,t] + FPR[1,t] )\n",
    "    if recall[2,t] + FPR[2,t] == 0:\n",
    "        precision[2,t] = 1\n",
    "    else:\n",
    "        precision[2,t] = recall[2,t]/(recall[2,t] + FPR[2,t] )\n",
    "    accuracy[:,t] = accuracy[:,t]/K\n",
    "    recall[:,t] = recall[:,t]/(len(np.argwhere(true_tao>0)))\n",
    "    FPR[:,t] = FPR[:,t]/(len(np.argwhere(true_tao<0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "\n",
    "\n",
    "def mean_ci(data_array):\n",
    "    means = []\n",
    "    lowers = []\n",
    "    uppers = []\n",
    "    for d in data_array:\n",
    "        mean = np.mean(d)\n",
    "        ci_low, ci_high = np.percentile(d, [2.5, 97.5])\n",
    "        means.append(mean)\n",
    "        lowers.append(mean - ci_low)\n",
    "        uppers.append(ci_high - mean)\n",
    "    return np.array(means), np.array(lowers), np.array(uppers)\n",
    "\n",
    "data = [\n",
    "    cost[0,1,:] - cost[0,0,:],\n",
    "    accuracy[1,:] - accuracy[0,:],\n",
    "    recall[1,:] - recall[0,:],\n",
    "    FPR[0,:] - FPR[1,:],\n",
    "    precision[1,:] - precision[0,:]\n",
    "]\n",
    "\n",
    "data1 = [\n",
    "    cost[0,2,:] - cost[0,0,:],\n",
    "    accuracy[2,:] - accuracy[0,:],\n",
    "    recall[2,:] - recall[0,:],\n",
    "    FPR[0,:] - FPR[2,:],\n",
    "    precision[2,:] - precision[0,:]\n",
    "]\n",
    "\n",
    "\n",
    "mean_dtr, err_low_dtr, err_up_dtr = mean_ci(data)\n",
    "mean_bayes, err_low_bayes, err_up_bayes = mean_ci(data1)\n",
    "\n",
    "x = np.arange(5)\n",
    "width = 0.2\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "\n",
    "ax.errorbar(x - width/2, mean_dtr, yerr=[err_low_dtr, err_up_dtr], fmt='o', \n",
    "            capsize=8, markersize=6, color='#495373', ecolor='#495373', label='DPTR', linewidth=2)\n",
    "\n",
    "\n",
    "ax.errorbar(x + width/2, mean_bayes, yerr=[err_low_bayes, err_up_bayes], fmt='o', \n",
    "            capsize=8, markersize=6, color='#E3738B', ecolor='#E3738B', label='Bayesian', linewidth=2)\n",
    "\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['OR', 'Accuracy', 'Recall', 'Specificity', 'Precision'], fontsize=15)\n",
    "\n",
    "\n",
    "ax.legend(fontsize=12, loc='upper right')\n",
    "ax.set_ylim(-1.1, 1)\n",
    "ax.tick_params(axis='y', labelsize=15)\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.savefig('Scenario3_basic.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Cost calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1, Change with anchor mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K = 100 # number of experiments\n",
    "K = 5\n",
    "T = 1000\n",
    "N = 10\n",
    "Z = t_dist.ppf(0.975,N)\n",
    "std_niose = 3\n",
    "anchor_set = [1,2,3,4,5]\n",
    "\n",
    "cost = np.zeros((len(anchor_set),3,T))\n",
    "for idx,anchor_mean in enumerate(anchor_set):\n",
    "    for t in tqdm(range(T)):\n",
    "\n",
    "        # generate true ATEs\n",
    "        true_tao = np.random.normal(anchor_mean, 3, K )\n",
    "        constant = np.random.normal(anchor_mean, 3)\n",
    "        optimal_cost = np.sum(true_tao[np.argwhere(true_tao>0)])\n",
    "\n",
    "        # generate data\n",
    "        feature = np.ones((N+K, K+1)) \n",
    "        feature[:, 1:] = np.random.binomial(1, 0.5, (N+K,K))\n",
    "\n",
    "        # generate label\n",
    "        label = constant + np.dot(feature[:,1:], true_tao) + np.random.normal(0, std_niose, N+K)\n",
    "\n",
    "        #estimated tao\n",
    "        model = sm.OLS(label, feature).fit()\n",
    "        estimated_tao = model.params\n",
    "        p_value = model.pvalues[1:]\n",
    "        cov_matrix = model.cov_params()\n",
    "\n",
    "        estimated_variance = np.zeros(K)\n",
    "        for i in range(K):\n",
    "            estimated_variance[i] = cov_matrix[i+1,i+1]\n",
    "        \n",
    "\n",
    "        hat_ATE = estimated_tao[1:]\n",
    "\n",
    "        \n",
    "        #estimated cost\n",
    "        decision1 = np.argwhere(hat_ATE>(Z*np.sqrt(estimated_variance)))\n",
    "        if optimal_cost == 0:\n",
    "            if len(decision1) == 0:\n",
    "                cost[idx,0,t] = 1\n",
    "            else:\n",
    "                cost[idx,0,t] = 0\n",
    "        else:\n",
    "            cost[idx,0,t] = np.sum(true_tao[decision1])/optimal_cost\n",
    "        tau_0 = np.mean(hat_ATE)\n",
    "\n",
    "        # Bayesian decision rule\n",
    "        bayesian_tao = np.zeros(K)\n",
    "        bayesian_beta = np.zeros(K)\n",
    "        denumerator = np.var(hat_ATE) - np.mean(estimated_variance)\n",
    "        decision3 = []\n",
    "  \n",
    "        for k in range(K):\n",
    "            if denumerator <= 0:\n",
    "                theta = 1\n",
    "                posteri_mean = hat_ATE[k]*theta + (1 - theta)*tau_0\n",
    "                posteri_var = 1/(1/estimated_variance[k])\n",
    "                dist = norm(loc=posteri_mean, scale=np.sqrt(posteri_var))\n",
    "                prob = dist.sf(0)  # survival function: P(X > x)\n",
    "                if prob > 1 - 0.025:\n",
    "                    decision3.append(k)\n",
    "            else:\n",
    "                bayesian_beta[k] = max(N*estimated_variance[k]/denumerator,0)\n",
    "                theta = N/(N+bayesian_beta[k])\n",
    "                posteri_mean = hat_ATE[k]*theta + (1 - theta)*tau_0\n",
    "                posteri_var = 1/(1/denumerator+ 1/estimated_variance[k])\n",
    "                dist = norm(loc=posteri_mean, scale=np.sqrt(posteri_var))\n",
    "\n",
    "                prob = dist.sf(0)  # survival function: P(X > x)\n",
    "                if prob > 1 - 0.025:\n",
    "                    decision3.append(k)\n",
    "        if optimal_cost == 0:\n",
    "            if len(decision3) == 0:\n",
    "                cost[idx,2,t] = 1\n",
    "            else:\n",
    "                cost[idx,2,t] = 0\n",
    "        else:\n",
    "            cost[idx,2,t] = np.sum(true_tao[decision3])/optimal_cost\n",
    "\n",
    "        \n",
    "        \n",
    "        if tau_0 == 0:\n",
    "            cost[idx,1,t] = cost[idx,0,t]\n",
    "            continue\n",
    "        beta = N*np.mean(estimated_variance)/(np.var(hat_ATE) - np.mean(estimated_variance)) +  Z*N*np.sqrt(np.mean(estimated_variance))/tau_0\n",
    "        beta = max(0,beta)\n",
    "        theta = N/(N+beta)\n",
    "        shrunken_ATE = theta*hat_ATE + (1-theta)*tau_0\n",
    "        decision2 = np.argwhere(shrunken_ATE>(theta*Z*np.sqrt(estimated_variance)))\n",
    "\n",
    "        if optimal_cost == 0:\n",
    "            if len(decision2) == 0:\n",
    "                cost[idx,1,t] = 1\n",
    "            else:\n",
    "                cost[idx,1,t] = 0\n",
    "        else:\n",
    "            cost[idx,1,t] = np.sum(true_tao[decision2])/optimal_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "cost1 = np.mean(cost,axis=2)\n",
    "plt.xlabel(r'The value $\\tau_0$',fontsize=15)\n",
    "plt.ylabel('Optimality Ratio (OR)',fontsize=15)\n",
    "y3 = cost1[:,1]\n",
    "plt.plot(anchor_set, y3,  color = '#495373',marker = \"s\",label = \"DPTR\")\n",
    "\n",
    "y3 = cost1[:,2]\n",
    "plt.plot(anchor_set, y3, color = '#E3738B',marker = \"s\",label = \"Bayesian\",linestyle = '--')\n",
    "\n",
    "y3 = cost1[:,0]\n",
    "plt.plot(anchor_set, y3, color = '#8CA5EA',linestyle = '--', marker='o',label = \"IHT\")\n",
    "\n",
    "\n",
    "plt.xticks([1,2,3,4,5],fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.grid()\n",
    "plt.savefig('performance_compare_with_tau0_correlation_K_{}.png'.format(K),dpi=300,bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2, Change with variacne of error term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters setting\n",
    "K = 100\n",
    "T = 1000\n",
    "#Z = norm.ppf(0.975)\n",
    "N = 10\n",
    "Z = t_dist.ppf(0.975,N)\n",
    "anchor_mean  = 1\n",
    "std_noise_set = [1,2,3,4,5]\n",
    "\n",
    "\n",
    "cost = np.zeros((len(std_noise_set),3,T))\n",
    "anchor_mean = 1\n",
    "for idx,std_niose in enumerate(std_noise_set):\n",
    "    for t in tqdm(range(T)):\n",
    "        true_tao = np.random.normal(anchor_mean, 3, K )\n",
    "        constant = np.random.normal(anchor_mean, 3)\n",
    "        optimal_cost = np.sum(true_tao[np.argwhere(true_tao>0)])\n",
    "\n",
    "        # generate data\n",
    "        feature = np.ones((N+K, K+1)) \n",
    "        feature[:, 1:] = np.random.binomial(1, 0.5, (N+K,K))\n",
    "\n",
    "        # generate label\n",
    "        label = constant + np.dot(feature[:,1:], true_tao) + np.random.normal(0, std_niose, N+K)\n",
    "\n",
    "        #estimated tao\n",
    "        model = sm.OLS(label, feature).fit()\n",
    "        estimated_tao = model.params\n",
    "        p_value = model.pvalues[1:]\n",
    "        cov_matrix = model.cov_params()\n",
    "\n",
    "        estimated_variance = np.zeros(K)\n",
    "        for i in range(K):\n",
    "            estimated_variance[i] = cov_matrix[i+1,i+1]\n",
    "        #estimated_variance = np.sum((label - feature@estimated_tao)**2)/(N)*np.linalg.inv(feature.T@feature)\n",
    "\n",
    "        hat_ATE = estimated_tao[1:]\n",
    "\n",
    "        \n",
    "        #estimated cost\n",
    "        decision1 = np.argwhere(hat_ATE>(Z*np.sqrt(estimated_variance)))\n",
    "        if optimal_cost == 0:\n",
    "            if len(decision1) == 0:\n",
    "                cost[idx,0,t] = 1\n",
    "            else:\n",
    "                cost[idx,0,t] = 0\n",
    "        else:\n",
    "            cost[idx,0,t] = np.sum(true_tao[decision1])/optimal_cost\n",
    "        tau_0 = np.mean(hat_ATE)\n",
    "\n",
    "        \n",
    "        bayesian_tao = np.zeros(K)\n",
    "        bayesian_beta = np.zeros(K)\n",
    "        denumerator = np.var(hat_ATE) - np.mean(estimated_variance)\n",
    "        decision3 = []\n",
    "  \n",
    "        for k in range(K):\n",
    "            if denumerator <= 0:\n",
    "                theta = 1\n",
    "                posteri_mean = hat_ATE[k]*theta + (1 - theta)*tau_0\n",
    "                posteri_var = 1/(1/estimated_variance[k])\n",
    "                dist = norm(loc=posteri_mean, scale=np.sqrt(posteri_var))\n",
    "                prob = dist.sf(0)  # survival function: P(X > x)\n",
    "                if prob > 1 - 0.025:\n",
    "                    decision3.append(k)\n",
    "            else:\n",
    "                bayesian_beta[k] = max(N*estimated_variance[k]/denumerator,0)\n",
    "                theta = N/(N+bayesian_beta[k])\n",
    "                posteri_mean = hat_ATE[k]*theta + (1 - theta)*tau_0\n",
    "                posteri_var = 1/(1/denumerator+ 1/estimated_variance[k])\n",
    "                dist = norm(loc=posteri_mean, scale=np.sqrt(posteri_var))\n",
    "\n",
    "                prob = dist.sf(0)  # survival function: P(X > x)\n",
    "                if prob > 1 - 0.025:\n",
    "                    decision3.append(k)\n",
    "        if optimal_cost == 0:\n",
    "            if len(decision3) == 0:\n",
    "                cost[idx,2,t] = 1\n",
    "            else:\n",
    "                cost[idx,2,t] = 0\n",
    "        else:\n",
    "            cost[idx,2,t] = np.sum(true_tao[decision3])/optimal_cost\n",
    "\n",
    "        \n",
    "        \n",
    "        if tau_0 == 0:\n",
    "            cost[idx,1,t] = cost[idx,0,t]\n",
    "            continue\n",
    "        beta = N*np.mean(estimated_variance)/(np.var(hat_ATE) - np.mean(estimated_variance)) +  Z*N*np.sqrt(np.mean(estimated_variance))/tau_0\n",
    "        beta = max(0,beta)\n",
    "        theta = N/(N+beta)\n",
    "        shrunken_ATE = theta*hat_ATE + (1-theta)*tau_0\n",
    "        decision2 = np.argwhere(shrunken_ATE>(theta*Z*np.sqrt(estimated_variance))/np.sqrt(N))\n",
    "\n",
    "        if optimal_cost == 0:\n",
    "            if len(decision2) == 0:\n",
    "                cost[idx,1,t] = 1\n",
    "            else:\n",
    "                cost[idx,1,t] = 0\n",
    "        else:\n",
    "            cost[idx,1,t] = np.sum(true_tao[decision2])/optimal_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.mean(cost[:,0,:],axis=1)\n",
    "y2 = np.mean(cost[:,1,:],axis=1)\n",
    "y3 = np.mean(cost[:,2,:],axis=1)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.xlabel(r\"The standard deviation of noise $\\sigma$\",fontsize=15)\n",
    "plt.ylabel('Value of Data Pooling (VDP)',fontsize=15)\n",
    "\n",
    "plt.plot(std_noise_set, [y2[i]/y1[i] - 1 for i in range(5)], color = '#495373',linestyle = '--', marker='o',label = \"DPTR\")\n",
    "plt.plot(std_noise_set, [y3[i]/y1[i] - 1 for i in range(5)], color = '#E3738B',linestyle = '--', marker='o',label = \"Bayesian\")\n",
    "\n",
    "\n",
    "plt.xticks(std_noise_set,fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.grid()\n",
    "#plt.savefig('performance_compare_with_sigma1_correlation_K_{}.png'.format(K),dpi=300,bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
