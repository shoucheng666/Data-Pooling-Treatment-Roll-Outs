{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "from copy import deepcopy\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import scipy linear regression\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import t as t_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Boxplot in basic setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 100 # number of experiments\n",
    "T = 1000\n",
    "\n",
    "N = 10 # number of samples per experiment\n",
    "Z = t_dist.ppf(0.975,N)\n",
    "anchor_mean = 1\n",
    "std_niose = 3\n",
    "\n",
    "cost = np.zeros((2,T))\n",
    "accuracy = np.zeros((2,1000))\n",
    "recall = np.zeros((2,1000))\n",
    "FPR = np.zeros((2,1000))\n",
    "precision = np.zeros((2,1000))\n",
    "for t in tqdm(range(T)):\n",
    "\n",
    "    # generate true ATEs\n",
    "    true_tao = np.random.normal(anchor_mean, 3, K )\n",
    "    constant = np.random.normal(anchor_mean, 3)\n",
    "    optimal_cost = np.sum(true_tao[np.argwhere(true_tao>0)])\n",
    "\n",
    "    # generate data\n",
    "    feature = np.ones((N+K, K+1)) \n",
    "    feature[:, 1:] = np.random.binomial(1, 0.5, (N+K,K))\n",
    "\n",
    "    # generate label\n",
    "    label = constant + np.dot(feature[:,1:], true_tao) + np.random.normal(0, std_niose, N+K)\n",
    "\n",
    "    #IHT\n",
    "    model = sm.OLS(label, feature).fit()\n",
    "    estimated_tao = model.params\n",
    "    p_value = model.pvalues[1:]\n",
    "    cov_matrix = model.cov_params()\n",
    "\n",
    "    estimated_variance = np.zeros(K)\n",
    "    for i in range(K):\n",
    "        estimated_variance[i] = cov_matrix[i+1,i+1]\n",
    "\n",
    "    hat_ATE = estimated_tao[1:]\n",
    "\n",
    "    \n",
    "    #estimated cost\n",
    "    decision1 = np.argwhere(hat_ATE>(Z*np.sqrt(estimated_variance)))\n",
    "    cost[0,t] = np.sum(true_tao[decision1])/optimal_cost\n",
    "\n",
    "    \n",
    "    #DRT\n",
    "    tau_0 = np.mean(hat_ATE)\n",
    "    if tau_0 == 0:\n",
    "        cost[1,t] = cost[0,t]\n",
    "        continue\n",
    "    beta = N*np.mean(estimated_variance)/(np.var(hat_ATE) - np.mean(estimated_variance)) +  Z*N*np.sqrt(np.mean(estimated_variance))/tau_0\n",
    "    beta = max(0,beta)\n",
    "    theta = N/(N+beta)\n",
    "    shrunken_ATE = theta*hat_ATE + (1-theta)*tau_0\n",
    "    decision2 = np.argwhere(shrunken_ATE>(theta*Z*np.sqrt(estimated_variance)))\n",
    "\n",
    "    cost[1,t] = np.sum(true_tao[decision2])/optimal_cost\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    for k in range(K):\n",
    "        if (true_tao[k] < 0 and k not in decision1) or (true_tao[k] > 0 and k in decision1):\n",
    "            accuracy[0,t] += 1\n",
    "        if (true_tao[k] < 0 and k not in decision2) or (true_tao[k] > 0 and k in decision2):\n",
    "            accuracy[1,t] += 1\n",
    "        if true_tao[k] > 0 and k in decision1:\n",
    "            recall[0,t] += 1\n",
    "        if true_tao[k] > 0 and k in decision2:\n",
    "            recall[1,t] += 1\n",
    "        if true_tao[k] < 0 and k in decision1:\n",
    "            FPR[0,t] += 1\n",
    "        if true_tao[k] <0 and k in decision2:\n",
    "            FPR[1,t] += 1\n",
    "    if recall[0,t] + FPR[0,t] == 0:\n",
    "        precision[0,t] = 1\n",
    "    else:\n",
    "        precision[0,t] = recall[0,t]/(recall[0,t] + FPR[0,t] )\n",
    "    precision[1,t] = recall[1,t]/(recall[1,t] +FPR[1,t] )\n",
    "    accuracy[:,t] = accuracy[:,t]/K\n",
    "    recall[:,t] = recall[:,t]/(len(np.argwhere(true_tao>0)))\n",
    "    FPR[:,t] = FPR[:,t]/(len(np.argwhere(true_tao<0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "data = [cost[1,:] - cost[0,:],accuracy[1,:] - accuracy[0,:],recall[1,:] - recall[0,:],FPR[0,:] - FPR[1,:],precision[1,:] - precision[0,:]]\n",
    "\n",
    "bp = plt.boxplot(data,showfliers=False,showmeans=True,patch_artist=True)\n",
    "\n",
    "colors = [ '#9DB4CE','#EDA1A4','#FCB462','#7BC4C5','#893E81']\n",
    "colors1 = ['#A3A5A6' ,'#A3A5A6','#FFE8CE','#D9EEEE','#DCA5C3']\n",
    "\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_edgecolor(color)\n",
    "    \n",
    "for whisker, color in zip(bp['whiskers'], [colors[i // 2] for i in range(len(bp['whiskers']))]):\n",
    "    whisker.set_color(color)\n",
    "\n",
    "for cap, color in zip(bp['caps'], [colors[i // 2] for i in range(len(bp['caps']))]):\n",
    "    cap.set_color(color)\n",
    "\n",
    "for median, color in zip(bp['medians'], colors1):\n",
    "    median.set_color(color)\n",
    "\n",
    "for flier, color in zip(bp['fliers'], [colors[i // 2] for i in range(len(bp['fliers']))]):\n",
    "    flier.set_markerfacecolor(color)\n",
    "    flier.set_markeredgecolor(color)\n",
    "\n",
    "plt.ylim(-1.1,1)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.xticks([1, 2,3,4,5], ['OR','Accuracy','Recall','Specificity','Precision'],fontsize=15)\n",
    "\n",
    "\n",
    "plt.savefig('boxplot_basic_overlap.png',dpi = 300,bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Cost calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1, Change with anchor mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K = 100 # number of experiments\n",
    "K = 5\n",
    "T = 1000\n",
    "N = 10\n",
    "Z = t_dist.ppf(0.975,N)\n",
    "std_niose = 3\n",
    "anchor_set = [1,2,3,4,5]\n",
    "\n",
    "cost = np.zeros((len(anchor_set),3,T))\n",
    "for idx,anchor_mean in enumerate(anchor_set):\n",
    "    for t in tqdm(range(T)):\n",
    "\n",
    "        # generate true ATEs\n",
    "        true_tao = np.random.normal(anchor_mean, 3, K )\n",
    "        constant = np.random.normal(anchor_mean, 3)\n",
    "        optimal_cost = np.sum(true_tao[np.argwhere(true_tao>0)])\n",
    "\n",
    "        # generate data\n",
    "        feature = np.ones((N+K, K+1)) \n",
    "        feature[:, 1:] = np.random.binomial(1, 0.5, (N+K,K))\n",
    "\n",
    "        # generate label\n",
    "        label = constant + np.dot(feature[:,1:], true_tao) + np.random.normal(0, std_niose, N+K)\n",
    "\n",
    "        #estimated tao\n",
    "        model = sm.OLS(label, feature).fit()\n",
    "        estimated_tao = model.params\n",
    "        p_value = model.pvalues[1:]\n",
    "        cov_matrix = model.cov_params()\n",
    "\n",
    "        estimated_variance = np.zeros(K)\n",
    "        for i in range(K):\n",
    "            estimated_variance[i] = cov_matrix[i+1,i+1]\n",
    "        \n",
    "\n",
    "        hat_ATE = estimated_tao[1:]\n",
    "\n",
    "        \n",
    "        #estimated cost\n",
    "        decision1 = np.argwhere(hat_ATE>(Z*np.sqrt(estimated_variance)))\n",
    "        if optimal_cost == 0:\n",
    "            if len(decision1) == 0:\n",
    "                cost[idx,0,t] = 1\n",
    "            else:\n",
    "                cost[idx,0,t] = 0\n",
    "        else:\n",
    "            cost[idx,0,t] = np.sum(true_tao[decision1])/optimal_cost\n",
    "        tau_0 = np.mean(hat_ATE)\n",
    "\n",
    "        # Bayesian decision rule\n",
    "        bayesian_tao = np.zeros(K)\n",
    "        bayesian_beta = np.zeros(K)\n",
    "        denumerator = np.var(hat_ATE) - np.mean(estimated_variance)\n",
    "        decision3 = []\n",
    "  \n",
    "        for k in range(K):\n",
    "            if denumerator <= 0:\n",
    "                theta = 1\n",
    "                posteri_mean = hat_ATE[k]*theta + (1 - theta)*tau_0\n",
    "                posteri_var = 1/(1/estimated_variance[k])\n",
    "                dist = norm(loc=posteri_mean, scale=np.sqrt(posteri_var))\n",
    "                prob = dist.sf(0)  # survival function: P(X > x)\n",
    "                if prob > 1 - 0.025:\n",
    "                    decision3.append(k)\n",
    "            else:\n",
    "                bayesian_beta[k] = max(N*estimated_variance[k]/denumerator,0)\n",
    "                theta = N/(N+bayesian_beta[k])\n",
    "                posteri_mean = hat_ATE[k]*theta + (1 - theta)*tau_0\n",
    "                posteri_var = 1/(1/denumerator+ 1/estimated_variance[k])\n",
    "                dist = norm(loc=posteri_mean, scale=np.sqrt(posteri_var))\n",
    "\n",
    "                prob = dist.sf(0)  # survival function: P(X > x)\n",
    "                if prob > 1 - 0.025:\n",
    "                    decision3.append(k)\n",
    "        if optimal_cost == 0:\n",
    "            if len(decision3) == 0:\n",
    "                cost[idx,2,t] = 1\n",
    "            else:\n",
    "                cost[idx,2,t] = 0\n",
    "        else:\n",
    "            cost[idx,2,t] = np.sum(true_tao[decision3])/optimal_cost\n",
    "\n",
    "        \n",
    "        \n",
    "        if tau_0 == 0:\n",
    "            cost[idx,1,t] = cost[idx,0,t]\n",
    "            continue\n",
    "        beta = N*np.mean(estimated_variance)/(np.var(hat_ATE) - np.mean(estimated_variance)) +  Z*N*np.sqrt(np.mean(estimated_variance))/tau_0\n",
    "        beta = max(0,beta)\n",
    "        theta = N/(N+beta)\n",
    "        shrunken_ATE = theta*hat_ATE + (1-theta)*tau_0\n",
    "        decision2 = np.argwhere(shrunken_ATE>(theta*Z*np.sqrt(estimated_variance)))\n",
    "\n",
    "        if optimal_cost == 0:\n",
    "            if len(decision2) == 0:\n",
    "                cost[idx,1,t] = 1\n",
    "            else:\n",
    "                cost[idx,1,t] = 0\n",
    "        else:\n",
    "            cost[idx,1,t] = np.sum(true_tao[decision2])/optimal_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "cost1 = np.mean(cost,axis=2)\n",
    "plt.xlabel(r'The value $\\tau_0$',fontsize=15)\n",
    "plt.ylabel('Optimality Ratio (OR)',fontsize=15)\n",
    "y3 = cost1[:,1]\n",
    "plt.plot(anchor_set, y3,  color = '#495373',marker = \"s\",label = \"DTR\")\n",
    "\n",
    "y3 = cost1[:,2]\n",
    "plt.plot(anchor_set, y3, color = '#E3738B',marker = \"s\",label = \"Bayesian\",linestyle = '--')\n",
    "\n",
    "y3 = cost1[:,0]\n",
    "plt.plot(anchor_set, y3, color = '#8CA5EA',linestyle = '--', marker='o',label = \"IHT\")\n",
    "\n",
    "\n",
    "plt.xticks([1,2,3,4,5],fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.grid()\n",
    "plt.savefig('performance_compare_with_tau0_correlation_K_{}.png'.format(K),dpi=300,bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2, Change with variacne of error term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters setting\n",
    "K = 100\n",
    "T = 1000\n",
    "N = 10\n",
    "Z = t_dist.ppf(0.975,N)\n",
    "anchor_mean  = 1\n",
    "std_noise_set = [1,2,3,4,5]\n",
    "\n",
    "\n",
    "cost = np.zeros((len(std_noise_set),3,T))\n",
    "anchor_mean = 1\n",
    "for idx,std_niose in enumerate(std_noise_set):\n",
    "    for t in tqdm(range(T)):\n",
    "        # generate true ATEs\n",
    "        true_tao = np.random.normal(anchor_mean, 3, K )\n",
    "        constant = np.random.normal(anchor_mean, 3)\n",
    "        optimal_cost = np.sum(true_tao[np.argwhere(true_tao>0)])\n",
    "\n",
    "        # generate data\n",
    "        feature = np.ones((N+K+1, K+1)) \n",
    "        feature[:, 1:] = np.random.binomial(1, 0.5, (N+K+1,K))\n",
    "\n",
    "        # generate label\n",
    "        label = constant + np.dot(feature[:,1:], true_tao) + np.random.normal(0, std_niose, N+K+1)\n",
    "\n",
    "        #estimated tao\n",
    "        model = sm.OLS(label, feature).fit()\n",
    "        estimated_tao = model.params\n",
    "        p_value = model.pvalues[1:]\n",
    "        cov_matrix = model.cov_params()\n",
    "\n",
    "        estimated_variance = np.zeros(K)\n",
    "        for i in range(K):\n",
    "            estimated_variance[i] = cov_matrix[i+1,i+1]\n",
    "\n",
    "\n",
    "        hat_ATE = estimated_tao[1:]\n",
    "\n",
    "        #estimated cost\n",
    "        decision1 = np.argwhere(hat_ATE>(Z*np.sqrt(estimated_variance)))\n",
    "        if optimal_cost == 0:\n",
    "            if len(decision1) == 0:\n",
    "                cost[idx,0,t] = 1\n",
    "            else:\n",
    "                cost[idx,0,t] = 0\n",
    "        else:\n",
    "            cost[idx,0,t] = np.sum(true_tao[decision1])/optimal_cost\n",
    "    \n",
    "        \n",
    "        tau_0 = np.mean(hat_ATE)\n",
    "        if tau_0 == 0:\n",
    "            cost[idx,1,t] = cost[idx,0,t]\n",
    "            continue\n",
    "        beta = N*np.mean(estimated_variance)/(np.var(hat_ATE) - np.mean(estimated_variance)) +  Z*N*np.sqrt(np.mean(estimated_variance))/tau_0\n",
    "        beta = max(0,beta)\n",
    "        theta = N/(N+beta)\n",
    "        shrunken_ATE = theta*hat_ATE + (1-theta)*tau_0\n",
    "        decision2 = np.argwhere(shrunken_ATE>(Z*np.sqrt(estimated_variance)*theta))\n",
    "        if optimal_cost == 0:\n",
    "            if len(decision2) == 0:\n",
    "                cost[idx,1,t] = 1\n",
    "            else:\n",
    "                cost[idx,1,t] = 0\n",
    "        else:\n",
    "            cost[idx,1,t] = np.sum(true_tao[decision2])/optimal_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.mean(cost[:,0,:],axis=1)\n",
    "y2 = np.mean(cost[:,1,:],axis=1)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.xlabel(r\"The standard deviation of noise $\\sigma$\",fontsize=15)\n",
    "plt.ylabel('Value of Data Pooling (VDP)',fontsize=15)\n",
    "\n",
    "plt.plot(std_noise_set, [y2[i]/y1[i] - 1 for i in range(5)], color = '#8CA5EA',linestyle = '--', marker='o')\n",
    "\n",
    "plt.xticks(std_noise_set,fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.grid()\n",
    "plt.savefig('performance_compare_with_sigma1_correlation_K_{}.png'.format(K),dpi=300,bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
