{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import norm\n",
    "from copy import deepcopy\n",
    "from scipy.stats import t as t_dist\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Cost calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Change with prior mean - Uniform-Uniform setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 100 # number of experiments\n",
    "N = 10  # number of samples in each experiment\n",
    "std = 3 # standard deviation of noise\n",
    "f_x = 4 # number of historical features\n",
    "Z = t_dist.ppf(0.975,N - f_x - 2) # critical value for two-tailed test at 95% confidence level\n",
    "\n",
    "cost = np.zeros((5,5,1000))\n",
    "\n",
    "for index1,anchor_mean in enumerate([1,2,3,4,5]):\n",
    "    for time_seq in tqdm(range(1000)):\n",
    "\n",
    "        # Generate true parameters\n",
    "        true_tao = np.random.uniform(anchor_mean - np.sqrt(9*12)/2, anchor_mean + np.sqrt(9*12)/2, K)\n",
    "        optimal_cost = np.sum(true_tao[np.argwhere(true_tao>0)]) \n",
    "        ture_theta_vector = np.random.uniform(-0.3,0.5,(K,f_x + 1))\n",
    "\n",
    "        # Generate historical features and response variable\n",
    "        X = np.ones((K,f_x+2,N))\n",
    "        for i in range(K):\n",
    "            for j in range(N):\n",
    "                indicator = np.random.choice([0,1],1)\n",
    "                if indicator == 0:\n",
    "                    X[i,-1,j] = 0\n",
    "                else:\n",
    "                    X[i,-1,j] = 1\n",
    "            hist_feature = np.random.uniform(0,1,(f_x,N))\n",
    "            X[i,1:-1,:] = hist_feature\n",
    "        Y = np.zeros((K,N))\n",
    "        for i in range(K):\n",
    "            for j in range(N):\n",
    "                Y[i,j] = np.sum(ture_theta_vector[i] * X[i,0:-1,j]) + true_tao[i]*X[i,-1,j] + np.random.uniform(-np.sqrt(std**2*12)/2,np.sqrt(std**2*12)/2)\n",
    "\n",
    "        #ols\n",
    "        tao_hat = np.zeros(K)\n",
    "        variance = np.zeros(K)\n",
    "        p_value_list = np.zeros(K)\n",
    "        b_list = np.zeros(K)\n",
    "\n",
    "        variance_1 = np.zeros(K)\n",
    "\n",
    "        for k in range(K):\n",
    "            model = sm.OLS(Y[k], X[k].T).fit()\n",
    "            tao_hat[k] = model.params[-1]\n",
    "            p_value_list[k] = model.pvalues[-1]\n",
    "            b_list[k] = N*np.linalg.inv(X[k] @ X[k].T + (10**-5) * np.eye(X[k].shape[0]))[-1,-1]\n",
    "            variance[k] = np.sum(model.resid**2)/(N - f_x - 2)\n",
    "\n",
    "         \n",
    "\n",
    "        #pesonlised parameter and consistant parameter\n",
    "        tao_0 = np.mean(tao_hat)\n",
    "        beta_vector = np.zeros(K)\n",
    "\n",
    "        estimated_noise_variance = np.mean(variance)\n",
    "        denominator = np.mean((tao_hat - tao_0)**2) - estimated_noise_variance*np.mean(b_list)/N\n",
    "        for k in range(K):\n",
    "            beta_vector[k] = estimated_noise_variance*b_list[k]/denominator  + np.sqrt(N*estimated_noise_variance*b_list[k])*Z/tao_0\n",
    "        \n",
    "        numerator = np.mean(variance*b_list)\n",
    "        denominator1 = np.mean((tao_hat - tao_0)**2) - np.mean(variance*b_list)/N\n",
    "        beta_constant = numerator/denominator1 + np.sqrt(N*numerator)*Z/tao_0\n",
    "\n",
    "        #beyasian decision\n",
    "        decision4 = []\n",
    "  \n",
    "        for k in range(K):\n",
    "            if denominator1 <= 0:\n",
    "                theta = 1\n",
    "                posteri_mean = tao_hat[k]*theta + (1 - theta)*tao_0\n",
    "                posteri_var = 1/(N/(variance[k]*b_list[k]))\n",
    "                dist = norm(loc=posteri_mean, scale=np.sqrt(posteri_var))\n",
    "                prob = dist.sf(0)  # survival function: P(X > x)\n",
    "                if prob > 1 - 0.025:\n",
    "                    decision4.append(k)\n",
    "            else:\n",
    "                theta = N/(N+max((variance[k]*b_list[k])/denominator1,0))\n",
    "                posteri_mean = tao_hat[k]*theta + (1 - theta)*tao_0\n",
    "                posteri_var = 1/(1/denominator1+N/(variance[k]*b_list[k]))\n",
    "                dist = norm(loc=posteri_mean, scale=np.sqrt(posteri_var))\n",
    "                prob = dist.sf(0)  # survival function: P(X > x)\n",
    "                if prob > 1 - 0.025:\n",
    "                    decision4.append(k)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        beta_constant = max(0,beta_constant)\n",
    "        beta_vector = np.maximum(0,beta_vector)\n",
    "        \n",
    "        theta_list = N/(N+beta_vector)\n",
    "        theta = N/(N+beta_constant)\n",
    "      \n",
    "        tao_shunken_hat = tao_hat*theta + (1-theta)*tao_0\n",
    "\n",
    "        tao_shunken_hat1 = tao_hat*theta_list + (1-theta_list)*tao_0\n",
    "        \n",
    "       \n",
    "        decision1 = np.argwhere(tao_hat>(Z*np.sqrt(variance*b_list))/np.sqrt(N))\n",
    "        decision2 = np.argwhere(tao_shunken_hat>(Z*np.sqrt(variance*b_list)*theta)/np.sqrt(N))\n",
    "        decision3 = np.argwhere(tao_shunken_hat1>(Z*np.sqrt(variance*b_list)*theta_list)/np.sqrt(N))\n",
    "\n",
    "        cost[0,index1,time_seq] = np.sum(true_tao[decision1])/optimal_cost\n",
    "        cost[1,index1,time_seq] = np.sum(true_tao[decision2])/optimal_cost\n",
    "        cost[2,index1,time_seq] = np.sum(true_tao[decision3])/optimal_cost\n",
    "        cost[3,index1,time_seq] = np.sum(true_tao[decision4])/optimal_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.xlabel(r'The value $\\tau_0$',fontsize=15)\n",
    "plt.ylabel('Optimality Ratio (OR)',fontsize=15)\n",
    "x = [1,2,3,4,5]\n",
    "\n",
    "\n",
    "y3 = np.mean(cost[2],axis=1)\n",
    "plt.plot(x, y3, color = '#713948',marker = \"^\",label = \"DTR-P\")\n",
    "\n",
    "\n",
    "y3 = np.mean(cost[1],axis=1)\n",
    "plt.plot(x, y3, color = '#495373',linestyle = '-.',marker = \"s\",label = \"DTR\")\n",
    "\n",
    "y3 = np.mean(cost[3],axis=1)\n",
    "plt.plot(x, y3, color = '#E3738B',linestyle = '--',marker = \"s\",label = \"Bayesian\")\n",
    "\n",
    "\n",
    "\n",
    "y3 = np.mean(cost[0],axis=1)\n",
    "plt.plot(x, y3, color = '#8CA5EA',linestyle = '--', marker='o',label = \"IHT\")\n",
    "\n",
    "plt.xticks([1,2,3,4,5],fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.grid()\n",
    "plt.savefig('performance_compare_with_tau0_uniform_feature.png',dpi=300,bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Change with prior mean - Normal-Normal setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 100 # number of experiments\n",
    "N = 10 # number of samples in each experiment\n",
    "std = 3 # standard deviation of noise\n",
    "f_x = 4 # number of historical features\n",
    "Z = t_dist.ppf(0.975,N - f_x - 2)   # critical value for two-tailed test at 95% confidence level\n",
    "\n",
    "cost = np.zeros((5,5,1000))\n",
    "\n",
    "for index1,anchor_mean in enumerate([1,2,3,4,5]):\n",
    "    for time_seq in tqdm(range(1000)):\n",
    "\n",
    "        #gerenate ture parameters\n",
    "        true_tao = np.random.normal(anchor_mean,3, K)\n",
    "        optimal_cost = np.sum(true_tao[np.argwhere(true_tao>0)]) \n",
    "        ture_theta_vector = np.random.uniform(-0.3,0.5,(K,f_x + 1))\n",
    "\n",
    "        # Generate historical features and response variable\n",
    "        X = np.ones((K,f_x+2,N))\n",
    "        for i in range(K):\n",
    "            for j in range(N):\n",
    "                indicator = np.random.choice([0,1],1)\n",
    "                if indicator == 0:\n",
    "                    X[i,-1,j] = 0\n",
    "                else:\n",
    "                    X[i,-1,j] = 1\n",
    "            hist_feature = np.random.uniform(0,1,(f_x,N))\n",
    "            X[i,1:-1,:] = hist_feature\n",
    "        Y = np.zeros((K,N))\n",
    "        for i in range(K):\n",
    "            for j in range(N):\n",
    "                Y[i,j] = np.sum(ture_theta_vector[i] * X[i,0:-1,j]) + true_tao[i]*X[i,-1,j] + np.random.normal(0,std)\n",
    "\n",
    "        #ols\n",
    "        tao_hat = np.zeros(K)\n",
    "        variance = np.zeros(K)\n",
    "        p_value_list = np.zeros(K)\n",
    "        b_list = np.zeros(K)\n",
    "\n",
    "        variance_1 = np.zeros(K)\n",
    "\n",
    "        for k in range(K):\n",
    "            model = sm.OLS(Y[k], X[k].T).fit()\n",
    "            tao_hat[k] = model.params[-1]\n",
    "            p_value_list[k] = model.pvalues[-1]\n",
    "            b_list[k] = N*np.linalg.inv(X[k] @ X[k].T + (10**-5) * np.eye(X[k].shape[0]))[-1,-1]\n",
    "\n",
    "            variance[k] = np.sum(model.resid**2)/(N - f_x - 2)\n",
    "            \n",
    "        \n",
    "        #personalised parameter and consistant parameter\n",
    "        tao_0 = np.mean(tao_hat)\n",
    "        beta_vector = np.zeros(K)\n",
    "\n",
    "        estimated_noise_variance = np.mean(variance)\n",
    "        denominator = np.mean((tao_hat - tao_0)**2) - estimated_noise_variance*np.mean(b_list)/N\n",
    "        for k in range(K):\n",
    "            beta_vector[k] = estimated_noise_variance*b_list[k]/denominator  + np.sqrt(N*estimated_noise_variance*b_list[k])*Z/tao_0\n",
    "        \n",
    "        numerator = np.mean(variance*b_list)\n",
    "        denominator1 = np.mean((tao_hat - tao_0)**2) - np.mean(variance*b_list)/N\n",
    "        beta_constant = numerator/denominator1 + np.sqrt(N*numerator)*Z/tao_0\n",
    "\n",
    "        #bayesian decision\n",
    "        decision4 = []\n",
    "  \n",
    "        for k in range(K):\n",
    "            if denominator1 <= 0:\n",
    "                theta = 1\n",
    "                posteri_mean = tao_hat[k]*theta + (1 - theta)*tao_0\n",
    "                posteri_var = 1/(N/(variance[k]*b_list[k]))\n",
    "                dist = norm(loc=posteri_mean, scale=np.sqrt(posteri_var))\n",
    "                prob = dist.sf(0)  # survival function: P(X > x)\n",
    "                if prob > 1 - 0.025:\n",
    "                    decision4.append(k)\n",
    "            else:\n",
    "                theta = N/(N+max((variance[k]*b_list[k])/denominator1,0))\n",
    "                posteri_mean = tao_hat[k]*theta + (1 - theta)*tao_0\n",
    "                posteri_var = 1/(1/denominator1+N/(variance[k]*b_list[k]))\n",
    "                dist = norm(loc=posteri_mean, scale=np.sqrt(posteri_var))\n",
    "                prob = dist.sf(0)  # survival function: P(X > x)\n",
    "                if prob > 1 - 0.025:\n",
    "                    decision4.append(k)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        beta_constant = max(0,beta_constant)\n",
    "        beta_vector = np.maximum(0,beta_vector)\n",
    "        \n",
    "        theta_list = N/(N+beta_vector)\n",
    "        theta = N/(N+beta_constant)\n",
    "       \n",
    "        tao_shunken_hat = tao_hat*theta + (1-theta)*tao_0\n",
    "\n",
    "        tao_shunken_hat1 = tao_hat*theta_list + (1-theta_list)*tao_0\n",
    "    \n",
    "        \n",
    "        decision1 = np.argwhere(tao_hat>(Z*np.sqrt(variance*b_list))/np.sqrt(N))\n",
    "        decision2 = np.argwhere(tao_shunken_hat>(Z*np.sqrt(variance*b_list)*theta)/np.sqrt(N))\n",
    "        decision3 = np.argwhere(tao_shunken_hat1>(Z*np.sqrt(variance*b_list)*theta_list)/np.sqrt(N))\n",
    "\n",
    "        cost[0,index1,time_seq] = np.sum(true_tao[decision1])/optimal_cost\n",
    "        cost[1,index1,time_seq] = np.sum(true_tao[decision2])/optimal_cost\n",
    "        cost[2,index1,time_seq] = np.sum(true_tao[decision3])/optimal_cost\n",
    "        cost[3,index1,time_seq] = np.sum(true_tao[decision4])/optimal_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.xlabel(r'The value $\\tau_0$',fontsize=15)\n",
    "plt.ylabel('Optimality Ratio (OR)',fontsize=15)\n",
    "x = [1,2,3,4,5]\n",
    "\n",
    "\n",
    "y3 = np.mean(cost[2],axis=1)\n",
    "plt.plot(x, y3, color = '#713948',marker = \"^\",label = \"DTR-P\")\n",
    "\n",
    "\n",
    "y3 = np.mean(cost[1],axis=1)\n",
    "plt.plot(x, y3, color = '#495373',linestyle = '-.',marker = \"s\",label = \"DTR\")\n",
    "\n",
    "y3 = np.mean(cost[3],axis=1)\n",
    "plt.plot(x, y3, color = '#E3738B',linestyle = '--',marker = \"s\",label = \"Bayesian\")\n",
    "\n",
    "\n",
    "\n",
    "y3 = np.mean(cost[0],axis=1)\n",
    "plt.plot(x, y3, color = '#8CA5EA',linestyle = '--', marker='o',label = \"IHT\")\n",
    "\n",
    "plt.xticks([1,2,3,4,5],fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.grid()\n",
    "plt.savefig('performance_compare_with_tau0_feature.png',dpi=300,bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Change with number of expriments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = np.zeros((5,5,1000))\n",
    "\n",
    "anchor_mean = 1 # mean of the true parameter\n",
    "N = 10 # number of samples in each experiment\n",
    "std = 3 # standard deviation of noise\n",
    "f_x = 4 # number of historical features\n",
    "Z = t_dist.ppf(0.975,N - f_x - 2) # critical value for two-tailed test at 95% confidence level\n",
    "K_list = [20,40,60,80,100] # list of number of experiments\n",
    "\n",
    "for index1,K in enumerate(K_list):\n",
    "    for time_seq in tqdm(range(1000)):\n",
    "\n",
    "        # Generate true parameters\n",
    "        true_tao = np.random.normal(anchor_mean,3, K)\n",
    "        optimal_cost = np.sum(true_tao[np.argwhere(true_tao>0)]) \n",
    "        ture_theta_vector = np.random.uniform(-0.3,0.5,(K,f_x + 1))\n",
    "\n",
    "        # Generate historical features and response variable\n",
    "        X = np.ones((K,f_x+2,N))\n",
    "        for i in range(K):\n",
    "            for j in range(N):\n",
    "                indicator = np.random.choice([0,1],1)\n",
    "                if indicator == 0:\n",
    "                    X[i,-1,j] = 0\n",
    "                else:\n",
    "                    X[i,-1,j] = 1\n",
    "            hist_feature = np.random.uniform(0,1,(f_x,N))\n",
    "            X[i,1:-1,:] = hist_feature\n",
    "        Y = np.zeros((K,N))\n",
    "        for i in range(K):\n",
    "            for j in range(N):\n",
    "                Y[i,j] = np.sum(ture_theta_vector[i] * X[i,0:-1,j]) + true_tao[i]*X[i,-1,j] + np.random.normal(0,std)\n",
    "\n",
    "        #ols\n",
    "        tao_hat = np.zeros(K)\n",
    "        variance = np.zeros(K)\n",
    "        p_value_list = np.zeros(K)\n",
    "        b_list = np.zeros(K)\n",
    "\n",
    "        variance_1 = np.zeros(K)\n",
    "\n",
    "        for k in range(K):\n",
    "            model = sm.OLS(Y[k], X[k].T).fit()\n",
    "            tao_hat[k] = model.params[-1]\n",
    "            p_value_list[k] = model.pvalues[-1]\n",
    "            b_list[k] = N*np.linalg.inv(X[k] @ X[k].T + (10**-5) * np.eye(X[k].shape[0]))[-1,-1]\n",
    "\n",
    "            variance[k] = np.sum(model.resid**2)/(N - f_x - 2)\n",
    "\n",
    "\n",
    "        #personalised parameter and consistant parameter\n",
    "        tao_0 = np.mean(tao_hat)\n",
    "        beta_vector = np.zeros(K)\n",
    "\n",
    "        estimated_noise_variance = np.mean(variance)\n",
    "        denominator = np.mean((tao_hat - tao_0)**2) - estimated_noise_variance*np.mean(b_list)/N\n",
    "        for k in range(K):\n",
    "            beta_vector[k] = estimated_noise_variance*b_list[k]/denominator  + np.sqrt(N*estimated_noise_variance*b_list[k])*Z/tao_0\n",
    "        \n",
    "        numerator = np.mean(variance*b_list)\n",
    "        denominator1 = np.mean((tao_hat - tao_0)**2) - np.mean(variance*b_list)/N\n",
    "        beta_constant = numerator/denominator1 + np.sqrt(N*numerator)*Z/tao_0\n",
    "\n",
    "        #bayesian decision\n",
    "        decision4 = []\n",
    "  \n",
    "        for k in range(K):\n",
    "            if denominator1 <= 0:\n",
    "                theta = 1\n",
    "                posteri_mean = tao_hat[k]*theta + (1 - theta)*tao_0\n",
    "                posteri_var = 1/(N/(variance[k]*b_list[k]))\n",
    "                dist = norm(loc=posteri_mean, scale=np.sqrt(posteri_var))\n",
    "                prob = dist.sf(0)  # survival function: P(X > x)\n",
    "                if prob > 1 - 0.025:\n",
    "                    decision4.append(k)\n",
    "            else:\n",
    "                theta = N/(N+max((variance[k]*b_list[k])/denominator1,0))\n",
    "                posteri_mean = tao_hat[k]*theta + (1 - theta)*tao_0\n",
    "                posteri_var = 1/(1/denominator1+N/(variance[k]*b_list[k]))\n",
    "                dist = norm(loc=posteri_mean, scale=np.sqrt(posteri_var))\n",
    "                prob = dist.sf(0)  # survival function: P(X > x)\n",
    "                if prob > 1 - 0.025:\n",
    "                    decision4.append(k)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "       \n",
    "        beta_constant = max(0,beta_constant)\n",
    "        beta_vector = np.maximum(0,beta_vector)\n",
    "      \n",
    "        theta_list = N/(N+beta_vector)\n",
    "        theta = N/(N+beta_constant)\n",
    "     \n",
    "        tao_shunken_hat = tao_hat*theta + (1-theta)*tao_0\n",
    "\n",
    "        tao_shunken_hat1 = tao_hat*theta_list + (1-theta_list)*tao_0\n",
    "    \n",
    "        \n",
    "        decision1 = np.argwhere(tao_hat>(Z*np.sqrt(variance*b_list))/np.sqrt(N))\n",
    "        decision2 = np.argwhere(tao_shunken_hat>(Z*np.sqrt(variance*b_list)*theta)/np.sqrt(N))\n",
    "        decision3 = np.argwhere(tao_shunken_hat1>(Z*np.sqrt(variance*b_list)*theta_list)/np.sqrt(N))\n",
    "\n",
    "        cost[0,index1,time_seq] = np.sum(true_tao[decision1])/optimal_cost\n",
    "        cost[1,index1,time_seq] = np.sum(true_tao[decision2])/optimal_cost\n",
    "        cost[2,index1,time_seq] = np.sum(true_tao[decision3])/optimal_cost\n",
    "        cost[3,index1,time_seq] = np.sum(true_tao[decision4])/optimal_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.xlabel(r'The number of experiments $K$',fontsize=15)\n",
    "plt.ylabel('Optimality Ratio (OR)',fontsize=15)\n",
    "\n",
    "x = [20,40,60,80,100]\n",
    "y3 = np.mean(cost[2],axis=1)\n",
    "plt.plot(x, y3, color = '#713948',marker = \"^\",label = \"DTR-P\")\n",
    "\n",
    "\n",
    "y3 = np.mean(cost[1],axis=1)\n",
    "plt.plot(x, y3, color = '#495373',linestyle = '-.',marker = \"s\",label = \"DTR\")\n",
    "\n",
    "y3 = np.mean(cost[3],axis=1)\n",
    "plt.plot(x, y3, color = '#E3738B',linestyle = '--',marker = \"s\",label = \"Bayesian\")\n",
    "\n",
    "\n",
    "\n",
    "y3 = np.mean(cost[0],axis=1)\n",
    "plt.plot(x, y3, color = '#8CA5EA',linestyle = '--', marker='o',label = \"IHT\")\n",
    "\n",
    "plt.xticks(x,fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.grid()\n",
    "plt.savefig('performance_compare_with_K_feature.png',dpi=300,bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Change with sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 100 # number of experiments\n",
    "N_list = [10,15,20,25,30] # list of number of samples in each experiment\n",
    "cost = np.zeros((5,5,1000))\n",
    "\n",
    "anchor_mean = 1 # mean of the true parameter\n",
    "std = 3 # standard deviation of noise\n",
    "f_x = 4 # number of historical features\n",
    "Z = t_dist.ppf(0.975,N - f_x - 2) # critical value for two-tailed test at 95% confidence level\n",
    "\n",
    "for index1,N in enumerate(N_list):\n",
    "    for time_seq in tqdm(range(1000)):\n",
    "\n",
    "        # Generate true parameters\n",
    "        true_tao = np.random.normal(anchor_mean,3, K)\n",
    "        optimal_cost = np.sum(true_tao[np.argwhere(true_tao>0)]) \n",
    "        ture_theta_vector = np.random.uniform(-0.3,0.5,(K,f_x + 1))\n",
    "\n",
    "        # Generate historical features and response variable\n",
    "        X = np.ones((K,f_x+2,N))\n",
    "        for i in range(K):\n",
    "            for j in range(N):\n",
    "                indicator = np.random.choice([0,1],1)\n",
    "                if indicator == 0:\n",
    "                    X[i,-1,j] = 0\n",
    "                else:\n",
    "                    X[i,-1,j] = 1\n",
    "            hist_feature = np.random.uniform(0,1,(f_x,N))\n",
    "            X[i,1:-1,:] = hist_feature\n",
    "        Y = np.zeros((K,N))\n",
    "        for i in range(K):\n",
    "            for j in range(N):\n",
    "                Y[i,j] = np.sum(ture_theta_vector[i] * X[i,0:-1,j]) + true_tao[i]*X[i,-1,j] + np.random.normal(0,std)\n",
    "\n",
    "        #ols\n",
    "        tao_hat = np.zeros(K)\n",
    "        variance = np.zeros(K)\n",
    "        p_value_list = np.zeros(K)\n",
    "        b_list = np.zeros(K)\n",
    "\n",
    "        variance_1 = np.zeros(K)\n",
    "\n",
    "        for k in range(K):\n",
    "            model = sm.OLS(Y[k], X[k].T).fit()\n",
    "            tao_hat[k] = model.params[-1]\n",
    "            p_value_list[k] = model.pvalues[-1]\n",
    "            b_list[k] = N*np.linalg.inv(X[k] @ X[k].T + (10**-5) * np.eye(X[k].shape[0]))[-1,-1]\n",
    "\n",
    "            variance[k] = np.sum(model.resid**2)/(N - f_x - 2)\n",
    "\n",
    "\n",
    "        # personalised parameter and consistant parameter\n",
    "        tao_0 = np.mean(tao_hat)\n",
    "        beta_vector = np.zeros(K)\n",
    "\n",
    "        estimated_noise_variance = np.mean(variance)\n",
    "        denominator = np.mean((tao_hat - tao_0)**2) - estimated_noise_variance*np.mean(b_list)/N\n",
    "        for k in range(K):\n",
    "            beta_vector[k] = estimated_noise_variance*b_list[k]/denominator  + np.sqrt(N*estimated_noise_variance*b_list[k])*Z/tao_0\n",
    "        \n",
    "        numerator = np.mean(variance*b_list)\n",
    "        denominator1 = np.mean((tao_hat - tao_0)**2) - np.mean(variance*b_list)/N\n",
    "        beta_constant = numerator/denominator1 + np.sqrt(N*numerator)*Z/tao_0\n",
    "\n",
    "        # bayesian decision\n",
    "        decision4 = []\n",
    "  \n",
    "        for k in range(K):\n",
    "            if denominator1 <= 0:\n",
    "                theta = 1\n",
    "                posteri_mean = tao_hat[k]*theta + (1 - theta)*tao_0\n",
    "                posteri_var = 1/(N/(variance[k]*b_list[k]))\n",
    "                dist = norm(loc=posteri_mean, scale=np.sqrt(posteri_var))\n",
    "                prob = dist.sf(0)  # survival function: P(X > x)\n",
    "                if prob > 1 - 0.025:\n",
    "                    decision4.append(k)\n",
    "            else:\n",
    "                theta = N/(N+max((variance[k]*b_list[k])/denominator1,0))\n",
    "                posteri_mean = tao_hat[k]*theta + (1 - theta)*tao_0\n",
    "                posteri_var = 1/(1/denominator1+N/(variance[k]*b_list[k]))\n",
    "                dist = norm(loc=posteri_mean, scale=np.sqrt(posteri_var))\n",
    "                prob = dist.sf(0)  # survival function: P(X > x)\n",
    "                if prob > 1 - 0.025:\n",
    "                    decision4.append(k)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "       \n",
    "        beta_constant = max(0,beta_constant)\n",
    "        beta_vector = np.maximum(0,beta_vector)\n",
    "\n",
    "        theta_list = N/(N+beta_vector)\n",
    "        theta = N/(N+beta_constant)\n",
    "    \n",
    "        tao_shunken_hat = tao_hat*theta + (1-theta)*tao_0\n",
    "\n",
    "        tao_shunken_hat1 = tao_hat*theta_list + (1-theta_list)*tao_0\n",
    "    \n",
    "\n",
    "        decision1 = np.argwhere(tao_hat>(Z*np.sqrt(variance*b_list))/np.sqrt(N))\n",
    "        decision2 = np.argwhere(tao_shunken_hat>(Z*np.sqrt(variance*b_list)*theta)/np.sqrt(N))\n",
    "        decision3 = np.argwhere(tao_shunken_hat1>(Z*np.sqrt(variance*b_list)*theta_list)/np.sqrt(N))\n",
    "\n",
    "        cost[0,index1,time_seq] = np.sum(true_tao[decision1])/optimal_cost\n",
    "        cost[1,index1,time_seq] = np.sum(true_tao[decision2])/optimal_cost\n",
    "        cost[2,index1,time_seq] = np.sum(true_tao[decision3])/optimal_cost\n",
    "        cost[3,index1,time_seq] = np.sum(true_tao[decision4])/optimal_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.xlabel(r'Sample size $N$',fontsize=15)\n",
    "plt.ylabel('Optimality Ratio (OR)',fontsize=15)\n",
    "\n",
    "x = [10,15,20,25,30]\n",
    "y3 = np.mean(cost[2],axis=1)\n",
    "plt.plot(x, y3, color = '#713948',marker = \"^\",label = \"DTR-P\")\n",
    "\n",
    "\n",
    "y3 = np.mean(cost[1],axis=1)\n",
    "plt.plot(x, y3, color = '#495373',linestyle = '-.',marker = \"s\",label = \"DTR\")\n",
    "\n",
    "y3 = np.mean(cost[3],axis=1)\n",
    "plt.plot(x, y3, color = '#E3738B',linestyle = '--',marker = \"s\",label = \"Bayesian\")\n",
    "\n",
    "\n",
    "\n",
    "y3 = np.mean(cost[0],axis=1)\n",
    "plt.plot(x, y3, color = '#8CA5EA',linestyle = '--', marker='o',label = \"IHT\")\n",
    "\n",
    "plt.xticks(x,fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.grid()\n",
    "plt.savefig('performance_compare_with_N_feature.png',dpi=300,bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
