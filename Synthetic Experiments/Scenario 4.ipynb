{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "from copy import deepcopy\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom loss function \n",
    "def custom_loss(output, target, treatment):\n",
    "    error = torch.sum(output*treatment,dim=1)\n",
    "    loss = torch.mean((target - error)**2)\n",
    "    return loss\n",
    "\n",
    "# function to calculate the Phi value\n",
    "def Phi(x,theta,Gamma,treatment,y,k,device):\n",
    "    with torch.no_grad():\n",
    "        theta.eval()\n",
    "        a = torch.tensor(x, dtype=torch.float32).to(device)\n",
    "        output = theta(a).detach().cpu().numpy()\n",
    "    indicator = np.zeros(output.shape[0])\n",
    "    indicator[k + 1] = 1\n",
    "    term1 = np.dot(output,indicator)\n",
    "    term2 = (indicator.reshape(1,-1)) @ (np.linalg.inv(Gamma)) @ (2*(np.dot(output,treatment) - y)*treatment.reshape(-1,1))\n",
    "\n",
    "    return term1 - term2\n",
    "\n",
    "# function to split the data into S parts\n",
    "def data_split(S,Hist_feature,Hist_treatment,Hist_label):\n",
    "    N = Hist_feature.shape[0]\n",
    "    number_per_split = int(N/S)\n",
    "    data_index = np.arange(N)\n",
    "    np.random.shuffle(data_index)\n",
    "    feature_list = []\n",
    "    treatment_list = []\n",
    "    label_list = []\n",
    "\n",
    "    for i in range(S):\n",
    "        feature_list.append(Hist_feature[data_index[i*number_per_split:(i+1)*number_per_split],:])\n",
    "        treatment_list.append(Hist_treatment[data_index[i*number_per_split:(i+1)*number_per_split],:])\n",
    "        label_list.append(Hist_label[data_index[i*number_per_split:(i+1)*number_per_split]])\n",
    "    \n",
    "    return feature_list,treatment_list,label_list\n",
    "\n",
    "# A simple two-layer fully connected neural network\n",
    "class TwoLayerFCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(TwoLayerFCN, self).__init__()\n",
    "        # first layer: input layer to hidden layer\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        # second layer: hidden layer to output layer\n",
    "       \n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        # activation function\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # forward pass through the network\n",
    "        x = self.fc1(x)          \n",
    "        x = self.activation(x)   \n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(S,s,feature_list,treatment_list,label_list,dim_feature,K,device):\n",
    "    train_data_list = []\n",
    "    train_label_list = []\n",
    "    train_treatment_list = []\n",
    "    for i in range(S):\n",
    "        if i != s:\n",
    "            train_data_list.append(feature_list[i])\n",
    "            train_label_list.append(label_list[i])\n",
    "            train_treatment_list.append(treatment_list[i])\n",
    "    train_data_array = np.concatenate(train_data_list, axis=0)\n",
    "    train_label_array = np.concatenate(train_label_list, axis=0)\n",
    "    train_treatment_array = np.concatenate(train_treatment_list, axis=0)\n",
    "\n",
    "   \n",
    "    data = train_data_array\n",
    "    label = train_label_array\n",
    "    treatment = train_treatment_array\n",
    "    data = torch.tensor(data, dtype=torch.float32).to(device)\n",
    "    label = torch.tensor(label, dtype=torch.float32).to(device)\n",
    "    treatment = torch.tensor(treatment, dtype=torch.float32).to(device)\n",
    "    model = TwoLayerFCN(dim_feature, K+10, K+1).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    batch_size = 32\n",
    "\n",
    "    for epoch in range(10):\n",
    "        index = np.arange(data.shape[0])\n",
    "        np.random.shuffle(index)\n",
    "        batch_data = []\n",
    "        for i in range(data.shape[0]//batch_size):\n",
    "            if (i+1)*batch_size < data.shape[0]:\n",
    "                batch_data.append((data[index[i*batch_size:(i+1)*batch_size],:],treatment[index[i*batch_size:(i+1)*batch_size],:],label[index[i*batch_size:(i+1)*batch_size]]))\n",
    "            else:\n",
    "                batch_data.append((data[index[i*batch_size:],:],treatment[index[i*batch_size:],:],label[index[i*batch_size:]]))\n",
    "        for i in range(len(batch_data)):\n",
    "            model.train()\n",
    "            #optimizer.zero_grad()\n",
    "            data1,treatment1,label1 = batch_data[i]\n",
    "            output = model(data1)\n",
    "            #print(output.shape,treatment.shape)\n",
    "            loss = custom_loss(output, label1, treatment1)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "   \n",
    "    estimated_Gamma = 2 * np.dot(train_treatment_array.T, train_treatment_array) / train_treatment_array.shape[0] \n",
    "    \n",
    "    return model, estimated_Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_feature = 4 # number of features\n",
    "K = 5 # number of treatments\n",
    "Z = norm.ppf(0.975) # 95% confidence interval\n",
    "N = 100 # number of samples\n",
    "\n",
    "T = 1000 # number of iterations\n",
    "S = 2 # number of splits\n",
    "number_per_split = int((K+N)/S)   #number of samples per split\n",
    "noise_list = [1,2,3,4,5] # noise level\n",
    "\n",
    "true_ate_array   = np.zeros((T,K))\n",
    "estimated_phi = np.zeros((len(noise_list),T,K,S,number_per_split))\n",
    "device = torch.device('cpu')\n",
    "\n",
    "\n",
    "\n",
    "for t in tqdm(range(T)):\n",
    "# constant linear true function\n",
    "    constant_linear = np.random.uniform(-0.3,0.5,dim_feature)\n",
    "\n",
    "    # linear true function\n",
    "    cofficent_linear = np.random.uniform(-0.3,0.5,(K,dim_feature))\n",
    "\n",
    "    true_ate = np.sum(cofficent_linear[:,:]*0.5, axis=1)\n",
    "    true_ate_array[t] = true_ate\n",
    "\n",
    "\n",
    "    #generate data\n",
    "    Hist_feature = np.random.uniform(0,1,(K+N,dim_feature))\n",
    " \n",
    "\n",
    "    \n",
    "\n",
    "    Hist_treatment = np.random.binomial(1,0.5,(K+N,K+1))\n",
    "    Hist_treatment[:,0] = 1\n",
    "\n",
    "    for id,std in enumerate(noise_list):\n",
    "\n",
    "        #generate label\n",
    "        Hist_label = np.dot(Hist_feature,constant_linear.T) + np.sum(np.dot(Hist_feature,cofficent_linear.T)*Hist_treatment[:,1:],axis = 1) + np.random.normal(0,std,K+N)\n",
    "        #split data\n",
    "        feature_list,treatment_list,label_list = data_split(S,Hist_feature,Hist_treatment,Hist_label)\n",
    "\n",
    "        #train model\n",
    "        for s in range(S):\n",
    "            model,estimated_Gamma = train_model(S,s,feature_list,treatment_list,label_list,dim_feature,K,device)\n",
    "            #print(\"yes\")\n",
    "            feature_ate = feature_list[s]\n",
    "            treatment_ate = treatment_list[s]\n",
    "            label_ate = label_list[s]\n",
    "            output = model(torch.tensor(feature_ate, dtype=torch.float32).to(device)).cpu().detach().numpy()\n",
    "            indicator_matrix = np.eye(output.shape[1])[:, 1:K+1]\n",
    "            term1 = np.dot(output, indicator_matrix)\n",
    "            term2 = indicator_matrix.T @ np.linalg.inv(estimated_Gamma) @ (2*(np.sum(output*treatment_ate,axis = 1) - label_ate)*treatment_ate.T)  # shape: (K, N)\n",
    "            estimated_phi[id,t,:,s,:] = term1.T - term2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = np.zeros((5,2,T))\n",
    "for i in range(5):\n",
    "    for t in range(T):\n",
    "        hat_ATE = np.mean(estimated_phi[i,t],axis=(1,2))\n",
    "        estimated_variance1 = np.mean((estimated_phi[i,t] - np.tile(hat_ATE.reshape(K,1,1),(S,number_per_split)))**2,axis=(1,2))\n",
    "        estimated_variance = np.mean((estimated_phi[i,t] - np.tile(hat_ATE.reshape(K,1,1),(S,number_per_split)))**2)\n",
    "        true_tao = true_ate_array[t]\n",
    "        optimal_cost = np.sum(true_tao[np.argwhere(true_tao>0)])\n",
    "\n",
    "        estimated_variance = estimated_variance*N/(N+K)\n",
    "\n",
    "        decision1 = np.argwhere(hat_ATE>(Z*np.sqrt(estimated_variance1))/np.sqrt(N))\n",
    "        \n",
    "        if optimal_cost == 0:\n",
    "            if len(decision1) == 0:\n",
    "                cost[i,0,t] = 1\n",
    "            else:\n",
    "                cost[i,0,t] = 0\n",
    "        else:\n",
    "            cost[i,0,t] = np.sum(true_tao[decision1])/optimal_cost\n",
    "       \n",
    "        #DPTR\n",
    "        anchor_tau = np.mean(hat_ATE)\n",
    "        if anchor_tau == 0:\n",
    "            cost[i,1,t] = cost[i,0,t]\n",
    "            continue\n",
    "        beta = estimated_variance/(np.mean((hat_ATE - anchor_tau)**2) - estimated_variance/N) + Z*np.sqrt(N*estimated_variance)/anchor_tau\n",
    "        theta = N/(N+beta)\n",
    "        hat_ATE_shrunken = theta*hat_ATE + (1-theta)*anchor_tau\n",
    "        decision2 = np.argwhere(hat_ATE_shrunken>(theta*Z*np.sqrt(estimated_variance1))/np.sqrt(N))\n",
    "        if optimal_cost == 0:\n",
    "            if len(decision2) == 0:\n",
    "                cost[i,1,t] = 1\n",
    "            else:\n",
    "                cost[i,1,t] = 0\n",
    "        else:\n",
    "            cost[i,1,t] = np.sum(true_tao[decision2])/optimal_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
