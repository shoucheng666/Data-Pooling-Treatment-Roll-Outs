{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import t as t_dist\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from copy import deepcopy\n",
    "import statsmodels.api as sm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('criteo-uplift-v2.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [f'f{i}' for i in range(12)]\n",
    "feature_data = raw_data[features].copy()\n",
    "feature_data = np.array(feature_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median  = np.median(feature_data[:,0])\n",
    "list_1 = list(np.where(feature_data[:,0] > median)[0])\n",
    "list_2 = list(np.where(feature_data[:,0] <= median)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_groups = np.zeros((feature_data.shape[0],feature_data.shape[1]))\n",
    "for j in range(feature_data.shape[1]):\n",
    "    median  = np.median(feature_data[:,j])\n",
    "    list_1 = list(np.where(feature_data[:,j] > median)[0])\n",
    "    list_2 = list(np.where(feature_data[:,j] < median)[0])\n",
    "    list_3 = list(np.where(feature_data[:,j] == median)[0])\n",
    "    if len(list_3) != 0:\n",
    "        sum_1 = len(list_1)\n",
    "        sum_2 = len(list_2)\n",
    "        if sum_1 > sum_2:\n",
    "            a = sum_1 - sum_2\n",
    "            # generate random permutation, then split\n",
    "            perm = np.random.permutation(list_3)\n",
    "            split_idx = int((len(list_3) + a) / 2)\n",
    "\n",
    "            list_temp1 = perm[:split_idx]  # select first half\n",
    "            list_temp2 = perm[split_idx:]  # remaining half\n",
    "\n",
    "            # directly extend list_2 and list_1\n",
    "            list_2.extend(list_temp1)\n",
    "            list_1.extend(list_temp2)\n",
    "        else:\n",
    "            a = sum_2 - sum_1\n",
    "            # generate random permutation, then split\n",
    "            perm = np.random.permutation(list_3)\n",
    "            split_idx = int((len(list_3) + a) / 2)\n",
    "\n",
    "            list_temp1 = perm[:split_idx]  # select first half\n",
    "            list_temp2 = perm[split_idx:]\n",
    "\n",
    "            # directly extend list_1 and list_2\n",
    "            list_1.extend(list_temp1)\n",
    "            list_2.extend(list_temp2)\n",
    "    binary_groups[list_1,j] = 1\n",
    "    binary_groups[list_2,j] = 0   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgroup_labels = np.apply_along_axis(lambda row: ''.join(row.astype(str)), axis=1, arr=binary_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['subgroup_labels'] = pd.Series(subgroup_labels, dtype=\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_data_list = []\n",
    "\n",
    "for outcome in [\"visit\"]:\n",
    "    pop_data = []\n",
    "    for subgroup, group_df in raw_data.groupby(\"subgroup_labels\"):\n",
    "        treated = np.array(group_df[group_df[\"treatment\"] == 1][outcome].values)\n",
    "        control = np.array(group_df[group_df[\"treatment\"] == 0][outcome].values)\n",
    "\n",
    "        \n",
    "        if len(treated) + len(control) > 1000:\n",
    "            pop_data.append([treated, control])\n",
    "    pop_data_list.append(pop_data)\n",
    "\n",
    "\n",
    "pop_data_visit = pop_data_list[0]\n",
    "true_tao_visit = []\n",
    "for i in range(len(pop_data_visit)):\n",
    "    tau1 = pop_data_visit[i][0]\n",
    "    tau2 = pop_data_visit[i][1]\n",
    "    true_tao_visit.append(np.mean(tau1) - np.mean(tau2))\n",
    "true_tao1_visit = np.array(true_tao_visit)\n",
    "\n",
    "weight_visit = []\n",
    "for i in range(len(pop_data_visit)):\n",
    "    tau1 = pop_data_visit[i][0]\n",
    "    tau2 = pop_data_visit[i][1]\n",
    "    weight_visit.append(len(tau1) + len(tau2))\n",
    "weight_visit = np.array(weight_visit)\n",
    "weight_visit = weight_visit/np.sum(weight_visit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(true_tao1_visit, color = '#8CA5EA' , bins=20)\n",
    "plt.xlabel('True HTEs')\n",
    "plt.ylabel(\"Number\")\n",
    "plt.savefig('true_ate_in_criteo.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1000\n",
    "N_list = [10,15,20,25,30]\n",
    "cost = np.zeros((len(N_list),4,T))\n",
    "decision_right_rate = np.zeros((len(N_list),3,2,T))\n",
    "#N = 20\n",
    "true_tao1 = deepcopy(true_tao1_visit)\n",
    "pop_data = deepcopy(pop_data_visit)\n",
    "weight = deepcopy(weight_visit)\n",
    "\n",
    "\n",
    "K = true_tao1.shape[0]\n",
    "tau_min = 0\n",
    "true_tao = true_tao1 - tau_min\n",
    "optimal_cost = np.sum(true_tao[np.argwhere(true_tao>0)]*weight[np.argwhere(true_tao>0)])\n",
    "\n",
    "estimated_tau = np.zeros((len(N_list),T,K))\n",
    "calculte_zeros = np.zeros((2,T))\n",
    "alpha = 0.05\n",
    "Z = norm.ppf( 1 - alpha/2)\n",
    "for idx, N in enumerate(N_list):\n",
    "    for t in tqdm(range(T)):\n",
    "        #hist_data = np.zeros((K,N,2))\n",
    "        tao_hat = np.zeros(K)\n",
    "        variance = np.zeros(K)\n",
    "        #upper_bound_list = np.zeros(K)\n",
    "        p_value_list = np.ones(K)\n",
    "        \n",
    "        group_hist = []\n",
    "        for k in range(K):\n",
    "            group_1 = np.array(np.random.choice(pop_data[k][0],int(N/2),replace=True))\n",
    "            group_0 = np.array(np.random.choice(pop_data[k][1],N - int(N/2),replace=True))\n",
    "            group_hist.append([group_1,group_0])\n",
    "            \n",
    "            diff_mean = group_1.mean() - group_0.mean()\n",
    "            if np.std(group_1) == 0 and np.std(group_0) == 0:\n",
    "                p_value = 0\n",
    "            else:\n",
    "                t_stat, p_value = ttest_ind(group_1, group_0, equal_var = False) \n",
    "            tao_hat[k] = diff_mean\n",
    "            p_value_list[k] = p_value\n",
    "            variance[k] = N*(group_1.var(ddof=1) / len(group_1) + group_0.var(ddof=1) / len(group_0))\n",
    "\n",
    "        decision1 = np.intersect1d(np.argwhere(p_value_list<alpha), np.argwhere(tao_hat>tau_min))\n",
    "        #decision1 = np.intersect1d(decision1,select_list)\n",
    "            \n",
    "        tao_0 = np.mean(tao_hat)\n",
    "        numerator = np.mean(variance)\n",
    "        denumerator = np.mean((tao_hat - tao_0)**2) - numerator/N\n",
    "\n",
    "        bayesian_tao = np.zeros(K)\n",
    "        bayesian_beta = np.zeros(K)\n",
    "        #p_value_list_bayesian = np.zeros(K)\n",
    "        decision3 = []\n",
    "        # #bayesian_variance = np.zeros(K)\n",
    "        for k in range(K):\n",
    "            if denumerator <= 0:\n",
    "                theta = 1\n",
    "                posteri_mean = tao_hat[k]*theta + (1 - theta)*tao_0\n",
    "                posteri_var = variance[k]/N\n",
    "                if posteri_mean > norm.ppf(0.975)*np.sqrt(posteri_var):\n",
    "                    decision3.append(k)\n",
    "\n",
    "            else:\n",
    "                bayesian_beta[k] = max(variance[k]/denumerator,0)\n",
    "                theta = N/(N+bayesian_beta[k])\n",
    "                posteri_mean = tao_hat[k]*theta + (1 - theta)*tao_0\n",
    "                posteri_var = theta*variance[k]/N\n",
    "                if posteri_mean > norm.ppf(0.975)*np.sqrt(posteri_var):\n",
    "                    decision3.append(k)\n",
    "\n",
    "             \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        if tao_0 == 0 or denumerator == 0:\n",
    "            beta = 0\n",
    "        else:\n",
    "            beta = numerator/denumerator + Z*np.sqrt(N*numerator)/tao_0\n",
    "        \n",
    "        beta = max(0,beta)\n",
    "        #print(beta)\n",
    "        theta = N/(N+beta)\n",
    "        tao_shunken_hat = np.zeros(K)\n",
    "        p_value_list_shrunken = np.ones(K)\n",
    "\n",
    "        for k in range(K):\n",
    "            group_11 = theta*group_hist[k][0] + (1-theta)*tao_0\n",
    "            group_00 = theta*group_hist[k][1]\n",
    "            if np.std(group_11) == 0 and np.std(group_00) == 0:\n",
    "                p_value = 0\n",
    "            else:\n",
    "                t_stat, p_value = ttest_ind(group_11, group_00, equal_var = False)\n",
    "\n",
    "            diff_mean1 = group_11.mean() - group_00.mean()\n",
    "            tao_shunken_hat[k] = diff_mean1\n",
    "            p_value_list_shrunken[k] = p_value\n",
    "        decision2 = np.intersect1d(np.argwhere(p_value_list_shrunken<alpha), np.argwhere(tao_shunken_hat>tau_min))\n",
    "      \n",
    "        cost[idx,0,t] = np.sum(true_tao[decision1]*weight[decision1])/optimal_cost\n",
    "        cost[idx,1,t] = np.sum(true_tao[decision2]*weight[decision2])/optimal_cost\n",
    "        cost[idx,2,t] = np.sum(true_tao[decision3]*weight[decision3])/optimal_cost\n",
    "\n",
    "\n",
    "        negative_right1 = 0\n",
    "        negative_right2 = 0\n",
    "        negative_right3 = 0\n",
    "        positive_right1 = 0\n",
    "        positive_right2 = 0\n",
    "        positive_right3 = 0\n",
    "        for k in range(K):\n",
    "            if true_tao[k] < 0 and k not in decision1:\n",
    "                negative_right1 += 1\n",
    "            if true_tao[k] < 0 and k not in decision2:\n",
    "                negative_right2 += 1\n",
    "            if true_tao[k] < 0 and k not in decision3:\n",
    "                negative_right3 += 1\n",
    "            if true_tao[k] > 0 and k in decision1:\n",
    "                positive_right1 += 1\n",
    "            if true_tao[k] > 0 and k in decision2:\n",
    "                positive_right2 += 1\n",
    "            if true_tao[k] > 0 and k in decision3:\n",
    "                positive_right3 += 1\n",
    "\n",
    "        decision_right_rate[idx,0,0,t] = positive_right1/(len(np.argwhere(true_tao>0)))\n",
    "        decision_right_rate[idx,1,0,t] = positive_right2/(len(np.argwhere(true_tao>0)))\n",
    "        decision_right_rate[idx,2,0,t] = positive_right3/(len(np.argwhere(true_tao>0)))\n",
    "        decision_right_rate[idx,0,1,t] = negative_right1/(len(np.argwhere(true_tao<0)))\n",
    "        decision_right_rate[idx,1,1,t] = negative_right2/(len(np.argwhere(true_tao<0)))\n",
    "        decision_right_rate[idx,2,1,t] = negative_right3/(len(np.argwhere(true_tao<0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
